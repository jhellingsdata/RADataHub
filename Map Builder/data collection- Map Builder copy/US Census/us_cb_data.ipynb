{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gabrielmelmed/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import requests, csv \n",
    "import us\n",
    "import pandas as pd\n",
    "import time\n",
    "from easymoney.money import EasyPeasy\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Downloading the variables table\n",
    "\n",
    "i. The first step is to the dictionary table for the ACS's variables and save it to a csv. The aim is to create a 'relational database' with a separate tables for values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_df = pd.read_csv('census_vars.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change !! into a space in the label col\n",
    "vars_df['label'] = vars_df['label'].str.replace('!!', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>for</td>\n",
       "      <td>Census API FIPS 'for' clause</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>in</td>\n",
       "      <td>Census API FIPS 'in' clause</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ucgid</td>\n",
       "      <td>Uniform Census Geography Identifier clause</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S0804_C04_068E</td>\n",
       "      <td>Estimate Public transportation (excluding taxi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S0503_C02_078E</td>\n",
       "      <td>Estimate Foreign born; Born in Europe Civilian...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18822</th>\n",
       "      <td>S2402_C02_035E</td>\n",
       "      <td>Estimate Male Full-time, year-round civilian e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18823</th>\n",
       "      <td>S1002_C04_004E</td>\n",
       "      <td>Estimate 60 years and over Percent distributio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18824</th>\n",
       "      <td>S0601_C02_009E</td>\n",
       "      <td>Estimate Native; born in state of residence To...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18825</th>\n",
       "      <td>S2411_C01_012E</td>\n",
       "      <td>Estimate Median earnings (dollars) Civilian em...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18826</th>\n",
       "      <td>S2302_C04_014E</td>\n",
       "      <td>Estimate Percent Families with own children un...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18827 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                index                                              label\n",
       "0                 for                       Census API FIPS 'for' clause\n",
       "1                  in                        Census API FIPS 'in' clause\n",
       "2               ucgid         Uniform Census Geography Identifier clause\n",
       "3      S0804_C04_068E  Estimate Public transportation (excluding taxi...\n",
       "4      S0503_C02_078E  Estimate Foreign born; Born in Europe Civilian...\n",
       "...               ...                                                ...\n",
       "18822  S2402_C02_035E  Estimate Male Full-time, year-round civilian e...\n",
       "18823  S1002_C04_004E  Estimate 60 years and over Percent distributio...\n",
       "18824  S0601_C02_009E  Estimate Native; born in state of residence To...\n",
       "18825  S2411_C01_012E  Estimate Median earnings (dollars) Civilian em...\n",
       "18826  S2302_C04_014E  Estimate Percent Families with own children un...\n",
       "\n",
       "[18827 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars_df = vars_df[['index', 'label']]\n",
    "vars_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the `census` Package \n",
    "\n",
    "For documentation, see [here](https://pypi.org/project/census/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gabrielmelmed/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# import necessary libraries\n",
    "import census\n",
    "import us\n",
    "from typing import Dict, List\n",
    "import pandas as pd\n",
    "from requests.exceptions import ConnectionError, Timeout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user input for api key\n",
    "api_key = input(\"Enter your API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the API key\n",
    "c = census.Census(api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The biggest issue is tracking down useful variable codes. I've started by creating this dictionary, which we can add to as we get more.\n",
    "\n",
    "The values are in a format that can be used for variable/table names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_of_interest = {\n",
    "    \"S1903_C03_015E\": \"median_income\",\n",
    "    \"S1903_C03_001E\": \"mean_income\",\n",
    "    \"B01001_001E\": \"population\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fips</th>\n",
       "      <th>name</th>\n",
       "      <th>abbr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>AZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>AR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>California</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>Colorado</td>\n",
       "      <td>CO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>CT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>Delaware</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>12</td>\n",
       "      <td>Florida</td>\n",
       "      <td>FL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>13</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>GA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>15</td>\n",
       "      <td>Hawaii</td>\n",
       "      <td>HI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>16</td>\n",
       "      <td>Idaho</td>\n",
       "      <td>ID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>17</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>IL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>18</td>\n",
       "      <td>Indiana</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>19</td>\n",
       "      <td>Iowa</td>\n",
       "      <td>IA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>20</td>\n",
       "      <td>Kansas</td>\n",
       "      <td>KS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>21</td>\n",
       "      <td>Kentucky</td>\n",
       "      <td>KY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>22</td>\n",
       "      <td>Louisiana</td>\n",
       "      <td>LA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>23</td>\n",
       "      <td>Maine</td>\n",
       "      <td>ME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>24</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>MD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>25</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>MA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>26</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>27</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>MN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>28</td>\n",
       "      <td>Mississippi</td>\n",
       "      <td>MS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>29</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>MO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>30</td>\n",
       "      <td>Montana</td>\n",
       "      <td>MT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>31</td>\n",
       "      <td>Nebraska</td>\n",
       "      <td>NE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>32</td>\n",
       "      <td>Nevada</td>\n",
       "      <td>NV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>33</td>\n",
       "      <td>New Hampshire</td>\n",
       "      <td>NH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>34</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>NJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>35</td>\n",
       "      <td>New Mexico</td>\n",
       "      <td>NM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>36</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>37</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>NC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>38</td>\n",
       "      <td>North Dakota</td>\n",
       "      <td>ND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>39</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>OH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>40</td>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>41</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>OR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>42</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>PA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>44</td>\n",
       "      <td>Rhode Island</td>\n",
       "      <td>RI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>45</td>\n",
       "      <td>South Carolina</td>\n",
       "      <td>SC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>46</td>\n",
       "      <td>South Dakota</td>\n",
       "      <td>SD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>47</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>TN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>48</td>\n",
       "      <td>Texas</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>49</td>\n",
       "      <td>Utah</td>\n",
       "      <td>UT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>50</td>\n",
       "      <td>Vermont</td>\n",
       "      <td>VT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>51</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>VA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>53</td>\n",
       "      <td>Washington</td>\n",
       "      <td>WA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>54</td>\n",
       "      <td>West Virginia</td>\n",
       "      <td>WV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>55</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>WI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>56</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>WY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>60</td>\n",
       "      <td>American Samoa</td>\n",
       "      <td>AS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>66</td>\n",
       "      <td>Guam</td>\n",
       "      <td>GU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>69</td>\n",
       "      <td>Northern Mariana Islands</td>\n",
       "      <td>MP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>72</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>PR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>78</td>\n",
       "      <td>Virgin Islands</td>\n",
       "      <td>VI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fips                      name abbr\n",
       "0      1                   Alabama   AL\n",
       "1      2                    Alaska   AK\n",
       "2      4                   Arizona   AZ\n",
       "3      5                  Arkansas   AR\n",
       "4      6                California   CA\n",
       "5      8                  Colorado   CO\n",
       "6      9               Connecticut   CT\n",
       "7     10                  Delaware   DE\n",
       "8     12                   Florida   FL\n",
       "9     13                   Georgia   GA\n",
       "10    15                    Hawaii   HI\n",
       "11    16                     Idaho   ID\n",
       "12    17                  Illinois   IL\n",
       "13    18                   Indiana   IN\n",
       "14    19                      Iowa   IA\n",
       "15    20                    Kansas   KS\n",
       "16    21                  Kentucky   KY\n",
       "17    22                 Louisiana   LA\n",
       "18    23                     Maine   ME\n",
       "19    24                  Maryland   MD\n",
       "20    25             Massachusetts   MA\n",
       "21    26                  Michigan   MI\n",
       "22    27                 Minnesota   MN\n",
       "23    28               Mississippi   MS\n",
       "24    29                  Missouri   MO\n",
       "25    30                   Montana   MT\n",
       "26    31                  Nebraska   NE\n",
       "27    32                    Nevada   NV\n",
       "28    33             New Hampshire   NH\n",
       "29    34                New Jersey   NJ\n",
       "30    35                New Mexico   NM\n",
       "31    36                  New York   NY\n",
       "32    37            North Carolina   NC\n",
       "33    38              North Dakota   ND\n",
       "34    39                      Ohio   OH\n",
       "35    40                  Oklahoma   OK\n",
       "36    41                    Oregon   OR\n",
       "37    42              Pennsylvania   PA\n",
       "38    44              Rhode Island   RI\n",
       "39    45            South Carolina   SC\n",
       "40    46              South Dakota   SD\n",
       "41    47                 Tennessee   TN\n",
       "42    48                     Texas   TX\n",
       "43    49                      Utah   UT\n",
       "44    50                   Vermont   VT\n",
       "45    51                  Virginia   VA\n",
       "46    53                Washington   WA\n",
       "47    54             West Virginia   WV\n",
       "48    55                 Wisconsin   WI\n",
       "49    56                   Wyoming   WY\n",
       "50    60            American Samoa   AS\n",
       "51    66                      Guam   GU\n",
       "52    69  Northern Mariana Islands   MP\n",
       "53    72               Puerto Rico   PR\n",
       "54    78            Virgin Islands   VI"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using the us library to get the fips codes, names, and abbreviations for all states\n",
    "states = us.states.mapping('fips', 'name')\n",
    "state_abbr = us.states.mapping('name', 'abbr')\n",
    "# turn into a dataframe\n",
    "states_df = pd.DataFrame(states.items(), columns=['fips', 'name'])\n",
    "states_df['abbr'] = states_df['name'].map(state_abbr)\n",
    "# turn fips numeric\n",
    "states_df['fips'] = states_df['fips'].astype(int)\n",
    "states_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'us' has no attribute 'counties'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# using the us library to get the fips codes and names for all counties\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m counties \u001b[38;5;241m=\u001b[39m \u001b[43mus\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcounties\u001b[49m\u001b[38;5;241m.\u001b[39mmapping(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfips\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# turn into a dataframe\u001b[39;00m\n\u001b[1;32m      4\u001b[0m counties_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(counties\u001b[38;5;241m.\u001b[39mitems(), columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfips\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'us' has no attribute 'counties'"
     ]
    }
   ],
   "source": [
    "# using the us library to get the fips codes and names for all counties\n",
    "counties = us.counties.mapping('fips', 'name')\n",
    "# turn into a dataframe\n",
    "counties_df = pd.DataFrame(counties.items(), columns=['fips', 'name'])\n",
    "# turn fips numeric\n",
    "counties_df['fips'] = counties_df['fips'].astype(int)\n",
    "counties_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a function to get all available data between 2010 and 2024 for all states:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acs1_state(c, series_code: str) -> pd.DataFrame:\n",
    "    \"\"\"Gets census data for all available years between 2010-2023.\"\"\"\n",
    "    data_rows = []\n",
    "    \n",
    "    for year in range(2010, 2024):\n",
    "        try:\n",
    "            data = c.acs1.get(series_code, {'for': 'state:*'}, year=year)\n",
    "            for row in data:\n",
    "                data_rows.append({\n",
    "                    'id': row['state'],\n",
    "                    'value': row[series_code],\n",
    "                    'year': year\n",
    "                })\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Failed to fetch {year}: {str(e)}\")\n",
    "            \n",
    "    return pd.DataFrame(data_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to fetch 2020: <!doctype html><html lang=\"en\"><head><title>HTTP Status 404 ? Not Found</title><style type=\"text/css\">body {font-family:Tahoma,Arial,sans-serif;} h1, h2, h3, b {color:white;background-color:#525D76;} h1 {font-size:22px;} h2 {font-size:16px;} h3 {font-size:14px;} p {font-size:12px;} a {color:black;} .line {height:1px;background-color:#525D76;border:none;}</style></head><body><h1>HTTP Status 404 ? Not Found</h1></body></html>\n"
     ]
    }
   ],
   "source": [
    "population_ts = get_acs1_state(c, 'B01003_001E')\n",
    "# add the state name and abbreviation from states_df\n",
    "population_ts = population_ts.merge(states_df, left_on='id', right_on='fips')\n",
    "population_ts.to_csv('us_states_population.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subject tables like mean and median income are not compatible with the census library. For this, we use an ordinary API loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_census_timeseries(api_key: str, variable: str) -> pd.DataFrame:\n",
    "    \"\"\"Creates time series DataFrame with state IDs and names.\"\"\"\n",
    "    data_rows = []\n",
    "    \n",
    "    for year in range(2010, 2024):\n",
    "        try:\n",
    "            base_url = f\"https://api.census.gov/data/{year}/acs/acs1/subject\"\n",
    "            params = {\n",
    "                \"get\": f\"NAME,{variable}\",\n",
    "                \"for\": \"state:*\",\n",
    "                \"key\": api_key\n",
    "            }\n",
    "            \n",
    "            response = requests.get(base_url, params=params)\n",
    "            data = response.json()\n",
    "            \n",
    "            year_df = pd.DataFrame(data[1:], columns=data[0])\n",
    "            \n",
    "            for _, row in year_df.iterrows():\n",
    "                data_rows.append({\n",
    "                    'id': row['state'],\n",
    "                    'name': row['NAME'],\n",
    "                    'value': row[variable],\n",
    "                    'year': year\n",
    "                })\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Failed to fetch {year} data: {str(e)}\")\n",
    "    \n",
    "    df = pd.DataFrame(data_rows)\n",
    "    df['id'] = pd.to_numeric(df['id'])\n",
    "    df['value'] = pd.to_numeric(df['value'])\n",
    "    df['year'] = pd.to_numeric(df['year'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'AL',\n",
       " 2: 'AK',\n",
       " 4: 'AZ',\n",
       " 5: 'AR',\n",
       " 6: 'CA',\n",
       " 8: 'CO',\n",
       " 9: 'CT',\n",
       " 10: 'DE',\n",
       " 12: 'FL',\n",
       " 13: 'GA',\n",
       " 15: 'HI',\n",
       " 16: 'ID',\n",
       " 17: 'IL',\n",
       " 18: 'IN',\n",
       " 19: 'IA',\n",
       " 20: 'KS',\n",
       " 21: 'KY',\n",
       " 22: 'LA',\n",
       " 23: 'ME',\n",
       " 24: 'MD',\n",
       " 25: 'MA',\n",
       " 26: 'MI',\n",
       " 27: 'MN',\n",
       " 28: 'MS',\n",
       " 29: 'MO',\n",
       " 30: 'MT',\n",
       " 31: 'NE',\n",
       " 32: 'NV',\n",
       " 33: 'NH',\n",
       " 34: 'NJ',\n",
       " 35: 'NM',\n",
       " 36: 'NY',\n",
       " 37: 'NC',\n",
       " 38: 'ND',\n",
       " 39: 'OH',\n",
       " 40: 'OK',\n",
       " 41: 'OR',\n",
       " 42: 'PA',\n",
       " 44: 'RI',\n",
       " 45: 'SC',\n",
       " 46: 'SD',\n",
       " 47: 'TN',\n",
       " 48: 'TX',\n",
       " 49: 'UT',\n",
       " 50: 'VT',\n",
       " 51: 'VA',\n",
       " 53: 'WA',\n",
       " 54: 'WV',\n",
       " 55: 'WI',\n",
       " 56: 'WY',\n",
       " 60: 'AS',\n",
       " 66: 'GU',\n",
       " 69: 'MP',\n",
       " 72: 'PR',\n",
       " 78: 'VI'}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the us library to get the fips codes and abbreviations for all states\n",
    "states = us.states.mapping('fips', 'abbr')\n",
    "# change id in the above dictionary to numeric\n",
    "states = {int(k): v for k, v in states.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to fetch 2010 data: Expecting value: line 1 column 1 (char 0)\n",
      "Failed to fetch 2011 data: Expecting value: line 1 column 1 (char 0)\n",
      "Failed to fetch 2012 data: Expecting value: line 1 column 1 (char 0)\n",
      "Failed to fetch 2013 data: Expecting value: line 1 column 1 (char 0)\n",
      "Failed to fetch 2014 data: Expecting value: line 1 column 1 (char 0)\n",
      "Failed to fetch 2015 data: Expecting value: line 1 column 1 (char 0)\n",
      "Failed to fetch 2016 data: Expecting value: line 1 column 1 (char 0)\n",
      "Failed to fetch 2020 data: Expecting value: line 1 column 1 (char 0)\n"
     ]
    }
   ],
   "source": [
    "# Usage\n",
    "median_income_ts = get_census_timeseries(api_key, 'S1903_C03_015E')\n",
    "\n",
    "# add the state abbr\n",
    "states = us.states.mapping('fips', 'abbr')\n",
    "states = {int(k): v for k, v in states.items()}\n",
    "median_income_ts['abbr'] = median_income_ts['id'].map(states)\n",
    "\n",
    "# save to a csv\n",
    "median_income_ts.to_csv(\"us_states_median_income.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to fetch 2010 data: Expecting value: line 1 column 1 (char 0)\n",
      "Failed to fetch 2011 data: Expecting value: line 1 column 1 (char 0)\n",
      "Failed to fetch 2012 data: Expecting value: line 1 column 1 (char 0)\n",
      "Failed to fetch 2013 data: Expecting value: line 1 column 1 (char 0)\n",
      "Failed to fetch 2014 data: Expecting value: line 1 column 1 (char 0)\n",
      "Failed to fetch 2015 data: Expecting value: line 1 column 1 (char 0)\n",
      "Failed to fetch 2016 data: Expecting value: line 1 column 1 (char 0)\n",
      "Failed to fetch 2020 data: Expecting value: line 1 column 1 (char 0)\n"
     ]
    }
   ],
   "source": [
    "# repeat for mean income\n",
    "mean_income_ts = get_census_timeseries(api_key, 'S1903_C03_001E')\n",
    "mean_income_ts['abbr'] = mean_income_ts['id'].map(states)\n",
    "mean_income_ts.to_csv(\"us_states_mean_income.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_census_data(c, series_code: str, dataset: str = 'acs1', geo_level: str = 'state') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Gets census data for all available years between 2010-2024.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    c : Census client object\n",
    "    series_code : str\n",
    "        The census series code to fetch\n",
    "    dataset : str\n",
    "        Census dataset to query (e.g., 'acs1', 'acs5', 'sf1', etc.)\n",
    "    geo_level : str\n",
    "        Geographic level for data ('state' or 'county')\n",
    "    \"\"\"\n",
    "    data_rows = []\n",
    "    \n",
    "    for year in range(2010, 2024):\n",
    "        try:\n",
    "            census_dataset = getattr(c, dataset)\n",
    "            \n",
    "            if geo_level == 'state':\n",
    "                data = census_dataset.get(series_code, {'for': 'state:*'}, year=year)\n",
    "                for row in data:\n",
    "                    data_rows.append({\n",
    "                        'state_id': row['state'],\n",
    "                        'value': row[series_code],\n",
    "                        'year': year\n",
    "                    })\n",
    "            else:  # county level\n",
    "                data = census_dataset.get(\n",
    "                    series_code,\n",
    "                    {'for': 'county:*', 'in': 'state:*'},\n",
    "                    year=year\n",
    "                )\n",
    "                for row in data:\n",
    "                    data_rows.append({\n",
    "                        'state_id': row['state'],\n",
    "                        'county_id': row['county'],\n",
    "                        'value': row[series_code],\n",
    "                        'year': year\n",
    "                    })\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Failed to fetch {year} data from {dataset}: {str(e)}\")\n",
    "            \n",
    "    return pd.DataFrame(data_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to fetch 2010 data from acs5st: error: error: unknown variable 'S1903_C03_015E'\n",
      "Failed to fetch 2011 data from acs5st: error: error: unknown variable 'S1903_C03_015E'\n",
      "Failed to fetch 2012 data from acs5st: error: error: unknown variable 'S1903_C03_015E'\n",
      "Failed to fetch 2013 data from acs5st: error: error: unknown variable 'S1903_C03_015E'\n",
      "Failed to fetch 2014 data from acs5st: error: error: unknown variable 'S1903_C03_015E'\n",
      "Failed to fetch 2015 data from acs5st: error: error: unknown variable 'S1903_C03_015E'\n",
      "Failed to fetch 2016 data from acs5st: error: error: unknown variable 'S1903_C03_015E'\n",
      "Failed to fetch 2023 data from acs5st: <!doctype html><html lang=\"en\"><head><title>HTTP Status 404 ? Not Found</title><style type=\"text/css\">body {font-family:Tahoma,Arial,sans-serif;} h1, h2, h3, b {color:white;background-color:#525D76;} h1 {font-size:22px;} h2 {font-size:16px;} h3 {font-size:14px;} p {font-size:12px;} a {color:black;} .line {height:1px;background-color:#525D76;border:none;}</style></head><body><h1>HTTP Status 404 ? Not Found</h1></body></html>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_id</th>\n",
       "      <th>value</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28</td>\n",
       "      <td>52689.0</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29</td>\n",
       "      <td>64776.0</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>65843.0</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>72191.0</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>65469.0</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>53</td>\n",
       "      <td>108285.0</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>54</td>\n",
       "      <td>71678.0</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>55</td>\n",
       "      <td>92974.0</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>56</td>\n",
       "      <td>92028.0</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>72</td>\n",
       "      <td>29240.0</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>312 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    state_id     value  year\n",
       "0         28   52689.0  2017\n",
       "1         29   64776.0  2017\n",
       "2         30   65843.0  2017\n",
       "3         31   72191.0  2017\n",
       "4         32   65469.0  2017\n",
       "..       ...       ...   ...\n",
       "307       53  108285.0  2022\n",
       "308       54   71678.0  2022\n",
       "309       55   92974.0  2022\n",
       "310       56   92028.0  2022\n",
       "311       72   29240.0  2022\n",
       "\n",
       "[312 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "med_income_state = get_census_data(c, 'S1903_C03_015E', geo_level='state', dataset='acs5st')\n",
    "med_income_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
